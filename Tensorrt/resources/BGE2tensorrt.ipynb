{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfaab55-7b04-4a31-bf5a-a5954a624617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting accelerate\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/d1/d5/0050b2820a1e709ffa623f9a9e8ae42d0903535f2150613cbfeb7f16932a/accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.0 in ./miniconda3/lib/python3.10/site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./miniconda3/lib/python3.10/site-packages (from accelerate) (2.1.2+cu118)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./miniconda3/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./miniconda3/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in ./miniconda3/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.64.1)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.0)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: triton==2.1.0 in ./miniconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a925f01e-1285-421f-b030-4888fd1c5ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting onnx\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/dd/5b/c4f95dbe652d14aeba9afaceb177e9ffc48ac3c03048dd3f872f26f07e34/onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/63/47/3dc0b075ab539f16b3d8b09df6b504f51836086ee709690a6278d791737d/onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycuda\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/61/69/f53a6624def08348778a7407683f44c2a9adfdb0b68b9a45f8213ff66c9d/pycuda-2024.1.2.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.20.2 in ./miniconda3/lib/python3.10/site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: numpy>=1.20 in ./miniconda3/lib/python3.10/site-packages (from onnx) (1.26.4)\n",
      "Collecting flatbuffers\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.10/site-packages (from onnxruntime) (24.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from onnxruntime) (1.12.1)\n",
      "Collecting coloredlogs\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytools>=2011.2\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/1f/d8/ffc428f577fa6e9ba0f90d801fac8243b0ed2013dabaa66ff522e02a0453/pytools-2024.1.16-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m600.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting mako\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/48/22/bc14c6f02e6dccaafb3eba95764c8f096714260c2aa5f76f654fd16a23dd/Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in ./miniconda3/lib/python3.10/site-packages (from pycuda) (4.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4 in ./miniconda3/lib/python3.10/site-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in ./miniconda3/lib/python3.10/site-packages (from mako->pycuda) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Building wheels for collected packages: pycuda\n",
      "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=663749 sha256=2d2192eeae8b0897b9cb9c5b9f993e54b6f421bdfd8c05a3bef1b4b2aed808a1\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/34/9f/ee6291ed0f5222d25ce4d2d79507768cbbc4624d717ced5759\n",
      "Successfully built pycuda\n",
      "Installing collected packages: flatbuffers, pytools, onnx, mako, humanfriendly, pycuda, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 mako-1.3.6 onnx-1.17.0 onnxruntime-1.20.1 pycuda-2024.1.2 pytools-2024.1.16\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install onnx onnxruntime pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb761480-dc7f-4021-8672-7ff277094c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT']=\"https://hf-mirror.com\"\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'BAAI/bge-reranker-large',\n",
    "    device_map=device,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abaee6f-ca07-43e2-adfe-1ad1e2df41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[[\"今天天气怎么样？\",\"你吃了吗\"]]\n",
    "output_ids = tokenizer(pairs, padding='max_length', truncation=True, return_tensors='pt', max_length=512)\n",
    "input_ids, attention_mask = output_ids['input_ids'], output_ids['attention_mask']\n",
    "scores = model(input_ids.to(device), attention_mask.to(device), return_dict=True).logits.view(-1, ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e13e351-dc47-4741-81bf-406b874f94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(input_ids.to(device), attention_mask.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d013bfca-902f-4e96-94ca-85668e79bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-7.7773]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fff77a-7b52-4317-bda5-e5bd5f9eaf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de5dc1b-dbcd-4e8d-82bb-e51fade8dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.7773], device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ca59dd-a3d6-4447-81f5-beae3e34cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0cf88d3-9079-4465-aa84-9b0706a6db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: onnx in ./miniconda3/lib/python3.10/site-packages (1.17.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./miniconda3/lib/python3.10/site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: numpy>=1.20 in ./miniconda3/lib/python3.10/site-packages (from onnx) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b57598f6-ee21-4201-b1c7-6b3ec8168550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in ./miniconda3/lib/python3.10/site-packages (2.1.2+cu118)\n",
      "Collecting torch\n",
      "  Using cached http://mirrors.aliyun.com/pypi/packages/2a/ef/834af4a885b31a0b32fff2d80e1e40f771e1566ea8ded55347502440786a/torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Requirement already satisfied: torchvision in ./miniconda3/lib/python3.10/site-packages (0.16.2+cu118)\n",
      "Collecting torchvision\n",
      "  Using cached http://mirrors.aliyun.com/pypi/packages/a2/f6/7ff89a9f8703f623f5664afd66c8600e3f09fe188e1e0b7e6f9a8617f865/torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./miniconda3/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/2c/14/91ae57cd4db3f9ef7aa99f4019cfa8d54cb4caa7e00975df6467e9725a9f/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Using cached http://mirrors.aliyun.com/pypi/packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/db/f7/97a9ea26ed4bbbfc2d470994b8b4f338ef663be97b8f677519ac195e113d/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ae/71/1c91302526c45ab494c23f61c7a84aa568b8c1f9d196efa5993957faf906/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ea/27/1795d86fe88ef397885f2e580ac37628ed058a92ed2c39dc8eac3adf0619/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/df/99/12cd266d6233f47d00daf3a72739872bdc10267d0383508b0b9c84a18bb6/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/9f/fd/713452cd72343f682b1c7b9321e23829f00b842ceaedcda96e742ea0b0b3/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/87/20/199b8713428322a2f22b722c62b8cc278cc53dffa9705d744484b5035ee9/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in ./miniconda3/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Collecting triton==3.1.0\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/98/29/69aa56dc0b2eb2602b553881e34243475ea2afd9699be042316842788ff5/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./miniconda3/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12.1\n",
      "    Uninstalling sympy-1.12.1:\n",
      "      Successfully uninstalled sympy-1.12.1\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2+cu118\n",
      "    Uninstalling torch-2.1.2+cu118:\n",
      "      Successfully uninstalled torch-2.1.2+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.2+cu118\n",
      "    Uninstalling torchvision-0.16.2+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.2+cu118\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 torchvision-0.20.1 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4dbc46d-d634-4e81-8724-f49f7d4d7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将pytorch模型转化为onnx引擎\n",
    "#1、定义输入张量的形状信息\n",
    "input_id_=torch.randint(2,1000,(1,512)).to('cuda')\n",
    "attention_mask_=torch.ones(1,512).long().to('cuda')\n",
    "#转化模型\n",
    "import torch\n",
    "torch.onnx.export(\n",
    "    model, #原模型\n",
    "    (input_id_.to(torch.int64),attention_mask_.to(torch.int64)), #输入张量，接受一个张量或者元组\n",
    "    \"autodl-tmp/BGE-4.onnx\",\n",
    "    export_params=True, #是否保存模型的权重信息\n",
    "    opset_version=17, #17支持INormalizationLayer，防止溢出\n",
    "    do_constant_folding=True,  #是否执行常量折叠优化\n",
    "    input_names=['input_ids','attention_mask'], #输入的名字\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input_ids':{0:'batch_size',1:'sequence_length'},\n",
    "        'attention_mask':{0:'batch_size',1:'sequence_length'},\n",
    "        'output':{0:'batch_size'}\n",
    "    }          #可变长度，在NLP中批次和序列长度都是可变长度\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e0bd469-1378-40a2-9a38-9b243b734506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将onnx转化为tensorrt引擎\n",
    "import tensorrt as trt\n",
    "logger=trt.Logger(trt.Logger.WARNING)\n",
    "trt.init_libnvinfer_plugins(logger,namespace='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8216be00-55e1-4c52-b006-3e1160694f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder=trt.Builder(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c760ce7-f4b7-4416-9183-f6f1fdd0d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=builder.create_builder_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505d614f-3994-4fc6-ae5f-4b2a634debdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set_flag(trt.BuilderFlag.FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae7c1a0-b797-40bc-ae07-488f0eb5355a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape(\"input_ids\", (1, 512),(8, 512),(16, 512))  # 输入的最小、默认批量大小、最大批次\n",
    "profile.set_shape(\"attention_mask\",(1,512),(8,512),(16,512))\n",
    "config.add_optimization_profile(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a33bb9-b3a3-4491-84ba-f74e44e52c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorrt_bindings.tensorrt.IBuilderConfig at 0x7f84782fa5b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37489a73-992f-4fe7-bd9f-6aa6b9f08e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE,1<<30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e4011ca-e28b-4c6c-bd41-e5a130e55c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=builder.create_network(1<<int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "409cf6ad-56a2-41b6-bf09-9565203c43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=trt.OnnxParser(network,logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19437341-091b-4308-8511-ee464fdbfd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/24/2024-20:27:40] [TRT] [W] ModelImporter.cpp:429: Make sure input input_ids has Int64 binding.\n",
      "[11/24/2024-20:27:40] [TRT] [W] ModelImporter.cpp:429: Make sure input attention_mask has Int64 binding.\n"
     ]
    }
   ],
   "source": [
    "success=parser.parse_from_file('autodl-tmp/BGE-4.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2858a6-2c19-48bc-9662-ce70835c972c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3de880-b801-4469-8c71-15087b3496ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(parser.num_errors):\n",
    "    print(parser.get_error(idx))\n",
    "if not success:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d345a87-00d5-4909-947b-1548b0ee4254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d44e2-c416-4484-acae-25eaf7b9da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_engine=builder.build_serialized_network(network,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae7b0cb-61a1-48ee-b933-099ec605f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('autodl-tmp/bge_engine','wb') as f:\n",
    "          f.write(serialized_engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
